{"cells":[{"cell_type":"markdown","metadata":{"id":"C0YnaxeLGCY4"},"source":["# __Assisted Practice: Training Deep Neural Networks on TensorFlow__\n","Building Deep Neural Networks on TensorFlow refers to the process of designing and constructing neural network models using the TensorFlow framework. This involves defining the architecture of the neural network, selecting appropriate layers and activation functions, specifying the optimization algorithm, and training the model using data.\n","\n","Let's understand how to build and train a neural network using TensorFlow."]},{"cell_type":"markdown","source":["\n","\n","## Steps to be followed:\n","1. Import the required libraries\n","2. Load and inspect the data\n","3. Build the model\n","4. Train the model"],"metadata":{"id":"saSuWUrGGPIa"}},{"cell_type":"markdown","source":["### Step 1: Import the required libraries\n","\n","- Import Pandas and NumPy packages.\n","- Import the TensorFlow package, which is used for text-based applications, image recognition, voice search, and many more.\n","- Import the Python package cv2, which is used for computer vision and image processing.\n","- Import the Python package matplotlib, which sets the padding between and around the subplots as well as the figure size.\n","- Import necessary libraries and modules for building a deep learning model using TensorFlow. It includes modules for convolutional and pooling layers, dropout, flattening, and dense layers.\n","- Import other libraries for data manipulation, visualization, and image processing."],"metadata":{"id":"zkfqjK31CXXV"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"Qz6slja9GCY8","executionInfo":{"status":"ok","timestamp":1719080146574,"user_tz":-330,"elapsed":17519,"user":{"displayName":"Aleena Raj","userId":"16635257578699511263"}}},"outputs":[],"source":["# Import TensorFlow and required layers for building the model\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n","\n","# Import other necessary libraries for data manipulation, visualization, and image processing\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","import os\n","import sys\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import seaborn as sns\n","import cv2\n","import IPython\n","from six.moves import urllib"]},{"cell_type":"markdown","metadata":{"id":"GYhwB5u8GCY-"},"source":["### Step 2: Load and inspect the data\n","\n","\n","- Load the California Housing dataset from **`fetch_california_housing`**.\n","- Split the dataset into two sets: the training set **train_features** and **train_labels** and the testing set **test_features** and **test_labels**.\n","- The testing set is used to evaluate the trained model's performance.\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"KaFEYTKKGCZA","executionInfo":{"status":"ok","timestamp":1719080148369,"user_tz":-330,"elapsed":1820,"user":{"displayName":"Aleena Raj","userId":"16635257578699511263"}}},"outputs":[],"source":["# Load the California Housing dataset from sklearn\n","from sklearn.datasets import fetch_california_housing\n","housing = fetch_california_housing()\n","\n","# Convert to pandas DataFrame\n","data = pd.DataFrame(housing.data, columns=housing.feature_names)\n","data['target'] = housing.target\n","\n","# Split the dataset into training and testing sets\n","train_data, test_data, train_labels, test_labels = train_test_split(data[housing.feature_names], data['target'], test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"duafEb2UGCZA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719080178457,"user_tz":-330,"elapsed":413,"user":{"displayName":"Aleena Raj","userId":"16635257578699511263"}},"outputId":"efbc245b-d46b-4c99-f3ac-908cd11fab28"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[-0.326196    0.34849025 -0.17491646 ...  0.05137609 -1.3728112\n","   1.27258656]\n"," [-0.03584338  1.61811813 -0.40283542 ... -0.11736222 -0.87669601\n","   0.70916212]\n"," [ 0.14470145 -1.95271028  0.08821601 ... -0.03227969 -0.46014647\n","  -0.44760309]\n"," ...\n"," [-0.49697313  0.58654547 -0.60675918 ...  0.02030568 -0.75500738\n","   0.59946887]\n"," [ 0.96545045 -1.07984112  0.40217517 ...  0.00707608  0.90651045\n","  -1.18553953]\n"," [-0.68544764  1.85617335 -0.85144571 ... -0.08535429  0.99543676\n","  -1.41489815]]\n"]}],"source":["# Standardize the features\n","scaler = StandardScaler()\n","train_features = scaler.fit_transform(train_data)\n","test_features = scaler.transform(test_data)\n","\n","# Print the standardized training features\n","print(train_features)"]},{"cell_type":"markdown","source":[" __Observation:__\n","\n","\n","- Here, we can see a few datasets from train dataset.\n","- The given array represents a multi-dimensional array containing numerical values.\n","- Each row in the array corresponds to a set of features or data points, while each column represents a specific feature or variable."],"metadata":{"id":"-_ZxZUEeF8iN"}},{"cell_type":"markdown","source":["### Step 3: Build the Model\n","Building the neural network requires:\n","- Configuring the layers of the model and compiling the model.\n","- Stacking a few layers together using **keras.Sequential**.\n","- Configuring the loss function, optimizer, and metrics to monitor.\n","These are added during the model's compile step.\n","\n","\n","\n","Terminologies:\n","- The **Loss** function measures how accurate the model is during training; we want to minimize this with the optimizer.\n","- One must **Optimize** how the model is updated based on the data it sees and its loss function.\n","- **Metrics** are used to monitor the training and testing steps."],"metadata":{"id":"v5fZchhYFbBZ"}},{"cell_type":"code","execution_count":4,"metadata":{"id":"kg01bCMMGCZC","executionInfo":{"status":"ok","timestamp":1719080417959,"user_tz":-330,"elapsed":397,"user":{"displayName":"Aleena Raj","userId":"16635257578699511263"}}},"outputs":[],"source":["# Function to build the neural network model\n","def build_model():\n","    model = keras.Sequential([\n","        # Input layer with 20 units and ReLU activation\n","        Dense(20, activation=tf.nn.relu, input_shape=[train_features.shape[1]]),\n","        # Output layer with 1 unit\n","        Dense(1)\n","    ])\n","\n","    # Compile the model with Adam optimizer and mean absolute error loss\n","    model.compile(optimizer=tf.optimizers.Adam(),\n","                  loss='mae',\n","                  metrics=['mean_absolute_error'])\n","    return model\n"]},{"cell_type":"markdown","metadata":{"id":"GkM_Ixa_GCZD"},"source":["### Step 4: Train the model\n","Training the neural network model requires the following steps:\n","\n","\n","- Define a custom callback class **PrintDot**, which prints a dot for every epoch during training.\n","\n","  `PrintDot` is a custom callback class in Keras that is used to provide visual feedback during the training process of a neural network. It prints a dot (.) for every epoch completed, and it prints a new line every 100 epochs. This helps in monitoring the progress of the training process in a simple and visual way without overwhelming the console with too much information.\n","\n","- Create an instance of the model using the **build_model** function.\n","\n","- Create an instance of EarlyStopping callback, which monitors the validation loss and stops training if it doesn't improve after a certain number of epochs (specified by patience).\n","\n","- Train the model using the training features and labels. It runs for 200 epochs, with a validation split of 0.1 (10% of the training data used for validation). The callbacks parameter includes **early_stop** and **PrintDot** callbacks.\n","\n","- Create a Pandas **DataFrame hist** from the history object returned by the model.fit method. It contains the recorded training and validation metrics.\n","\n","- Extract the last value of the validation mean absolute error (MAE) from the hist DataFrame and assign it to the variable mae_final.\n","\n","- Print the final MAE on the validation set, rounded to three decimal places."]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8WocKoO9GCZE","outputId":"8fe50642-db86-4166-af8b-5c25d136d3ab","executionInfo":{"status":"ok","timestamp":1719081211819,"user_tz":-330,"elapsed":167910,"user":{"displayName":"Aleena Raj","userId":"16635257578699511263"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","....................................................................................................\n","....................................................................................................\n","Final Mean Absolute Error on validation set: 0.585\n"]}],"source":["# Custom callback class to print a dot for every epoch\n","class PrintDot(keras.callbacks.Callback):\n","    def on_epoch_end(self, epoch, logs):\n","        if epoch % 100 == 0: print('')\n","        print('.', end='')\n","\n","# Build the model using the build_model function\n","model = build_model()\n","\n","# Early stopping callback to stop training if validation loss doesn't improve for 50 epochs\n","early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=50)\n","\n","# Train the model with training data, using 10% of the data for validation\n","history = model.fit(train_features, train_labels, epochs=200, verbose=0, validation_split=0.1,\n","                    callbacks=[early_stop, PrintDot()])\n","\n","# Create a Pandas DataFrame from the training history\n","hist = pd.DataFrame(history.history)\n","hist['epoch'] = history.epoch\n","\n","# Extract the final mean absolute error from the validation set\n","mae_final = float(hist['val_mean_absolute_error'].iloc[-1])\n","\n","print()\n","print('Final Mean Absolute Error on validation set: {}'.format(round(mae_final, 3)))\n","\n"]},{"cell_type":"markdown","source":["**Observation:**\n","\n","As shown, the final mean absolute error on the validation set is 0.369."],"metadata":{"id":"7r7uOD6jLYx-"}},{"cell_type":"markdown","source":["\n","- Evaluate the model's performance on the normalized test features and prints the mean absolute error (MAE) on the test set."],"metadata":{"id":"MZeUxYF9HML2"}},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LQbYz8kMGCZE","outputId":"9a7a0516-b961-4230-bf31-2e254b8cdd84","executionInfo":{"status":"ok","timestamp":1719081448465,"user_tz":-330,"elapsed":728,"user":{"displayName":"Aleena Raj","userId":"16635257578699511263"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["129/129 [==============================] - 0s 1ms/step - loss: 0.3639 - mean_absolute_error: 0.3639\n","Mean Absolute Error on test set: 0.364\n"]}],"source":["# Evaluate the model's performance on the test set\n","mae, _ = model.evaluate(test_features, test_labels)\n","print('Mean Absolute Error on test set: {}'.format(round(mae, 3)))"]},{"cell_type":"markdown","source":["**Observation:**\n","\n","The output indicates the following:\n","\n","- The evaluation was performed on the `test_features` and `test_labels`.\n","- The mean absolute error on the test set is also 0.3576.\n","- The mean absolute error, when rounded, is 0.358.\n","\n"],"metadata":{"id":"vCrX2XQzL1x3"}}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}